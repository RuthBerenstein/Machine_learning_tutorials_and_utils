{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/holy-grail-for-bias-variance-tradeoff-overfitting-underfitting-7fad64ab5d76?source=post_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Models \n",
    "## 2. Ensemble Models with Bagging and RandomForest\n",
    "\n",
    "Recommended reading:\n",
    "* https://towardsdatascience.com/holy-grail-for-bias-variance-tradeoff-overfitting-underfitting-7fad64ab5d76?source=post_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier, \\\n",
    "    AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_results(y, y_pred, name='', classes=['no', 'yes'], add_rep=False):\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "                        \n",
    "    cm = pd.DataFrame(confusion_matrix(y, y_pred), \n",
    "                      index=classes, \n",
    "                      columns=classes)\n",
    "\n",
    "    print(name + ' accuracy: ', round(acc,4),'\\n')\n",
    "    print(cm,'\\n')\n",
    "    if (add_rep):\n",
    "        print(classification_report(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "* https://towardsdatascience.com/simple-guide-for-ensemble-learning-methods-d87cc68705a2\n",
    "* https://towardsdatascience.com/holy-grail-for-bias-variance-tradeoff-overfitting-underfitting-7fad64ab5d76\n",
    "\n",
    "Ensemble models, combine the decisions from multiple models, to improve the overall performance. \n",
    "\n",
    "ensemble learning methods employ a group of models where the combined result out of them is almost always better in terms of prediction accuracy as compared to using a single model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Ensemble techniques\n",
    "Bagging and Boosting are advanced ensemble techniques. They are not working on the prediction of other models, as simple ensemble technique,but rather they create a new learning algorithm, from on a base learner algorithm. For example, if we choose a Decision classification tree, Bagging and Boosting would consist of a pool of decision trees.\n",
    "\n",
    "> sklearn.ensemble module http://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble \n",
    "\n",
    "### Bagging (Bootstrap Aggregating)\n",
    "Bagging is an ensemble method. Here are a rough scheme:\n",
    "\n",
    "1. Create random subset samples of the training data.\n",
    "2. Build a model ,Decision tree for example, and fit it to each sample.\n",
    "3. Combined multiple results by using simple ensemble methods as voting and avreging.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging demonstration\n",
    "For simple demonstration,lets code a bagging example on Base learner of Decision Tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    * applying multiple models for the same problem and then \n",
    "    * consider all the outcomes for the final resolution. \n",
    "    \n",
    "> Such a collection of models is called **ensemble**, and it has two main flavors:\n",
    "* averaging and \n",
    "* boosting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging (Bootstrap Aggregation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In English the term bootstrapping means \"to get something out of a situation using existing resources\"\n",
    "* in statistics it refers to the option of randomly resampling the data in order to create a collection of models. \n",
    "This means that bagging is similar to voting, with the difference that:\n",
    "* you choose a specific type of model (called **base model**), and then fit subsamples of your data to it **many times**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3220, 58)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_csv(\"spambase_csv.csv\")\n",
    "train, test = train_test_split(df, test_size=0.3)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[train.columns[:-1]]\n",
    "y_train = train[train.columns[-1]]\n",
    "X_test = test[test.columns[:-1]]\n",
    "y_test = test[test.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi = [train.sample(1000) for i in range(20)]\n",
    "Dti = [DecisionTreeClassifier(max_depth=5).fit(dfi[i][df.columns[:-1]], dfi[i][df.columns[-1]]) for i in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = train[train.columns[-1]].to_frame()\n",
    "test_predictions = test[test.columns[-1]].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,Dt in enumerate(Dti):\n",
    "    \n",
    "    predictions['Dt'+str(i)]  = Dt.predict(train[train.columns[:-1]])\n",
    "    test_predictions['Dt'+str(i)] = Dt.predict(test[test.columns[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3220, 3220)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(predictions[predictions.columns[1:]].sum(axis=1)>=5,1,0)), len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Dt0</th>\n",
       "      <th>Dt1</th>\n",
       "      <th>Dt2</th>\n",
       "      <th>Dt3</th>\n",
       "      <th>Dt4</th>\n",
       "      <th>Dt5</th>\n",
       "      <th>Dt6</th>\n",
       "      <th>Dt7</th>\n",
       "      <th>Dt8</th>\n",
       "      <th>...</th>\n",
       "      <th>Dt11</th>\n",
       "      <th>Dt12</th>\n",
       "      <th>Dt13</th>\n",
       "      <th>Dt14</th>\n",
       "      <th>Dt15</th>\n",
       "      <th>Dt16</th>\n",
       "      <th>Dt17</th>\n",
       "      <th>Dt18</th>\n",
       "      <th>Dt19</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2321</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4010</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class  Dt0  Dt1  Dt2  Dt3  Dt4  Dt5  Dt6  Dt7  Dt8  ...   Dt11  Dt12  \\\n",
       "740       1    0    0    0    1    1    0    0    1    1  ...      1     0   \n",
       "2321      0    0    0    0    0    0    0    0    0    0  ...      0     0   \n",
       "4010      0    0    0    0    0    0    0    0    0    0  ...      0     0   \n",
       "680       1    1    1    1    1    1    1    1    1    1  ...      1     1   \n",
       "3751      0    0    0    0    0    0    0    0    0    0  ...      0     0   \n",
       "\n",
       "      Dt13  Dt14  Dt15  Dt16  Dt17  Dt18  Dt19  pred  \n",
       "740      1     0     0     1     1     1     0     1  \n",
       "2321     0     0     0     0     1     0     0     0  \n",
       "4010     0     0     0     0     0     0     0     0  \n",
       "680      1     1     1     1     1     1     1     1  \n",
       "3751     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['pred'] = np.where(predictions[predictions.columns[1:]].sum(axis=1)>=5,1,0)\n",
    "\n",
    "predictions[::5].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Dt0</th>\n",
       "      <th>Dt1</th>\n",
       "      <th>Dt2</th>\n",
       "      <th>Dt3</th>\n",
       "      <th>Dt4</th>\n",
       "      <th>Dt5</th>\n",
       "      <th>Dt6</th>\n",
       "      <th>Dt7</th>\n",
       "      <th>Dt8</th>\n",
       "      <th>...</th>\n",
       "      <th>Dt10</th>\n",
       "      <th>Dt11</th>\n",
       "      <th>Dt12</th>\n",
       "      <th>Dt13</th>\n",
       "      <th>Dt14</th>\n",
       "      <th>Dt15</th>\n",
       "      <th>Dt16</th>\n",
       "      <th>Dt17</th>\n",
       "      <th>Dt18</th>\n",
       "      <th>Dt19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3449</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4200</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class  Dt0  Dt1  Dt2  Dt3  Dt4  Dt5  Dt6  Dt7  Dt8  ...   Dt10  Dt11  \\\n",
       "2644      0    0    0    0    0    1    0    0    0    0  ...      0     0   \n",
       "3449      0    0    0    0    0    0    0    0    0    0  ...      0     0   \n",
       "1529      1    1    1    1    1    1    1    1    1    1  ...      1     1   \n",
       "4200      0    0    0    0    0    0    0    0    0    0  ...      0     0   \n",
       "1515      1    1    1    1    1    1    1    1    1    1  ...      1     1   \n",
       "\n",
       "      Dt12  Dt13  Dt14  Dt15  Dt16  Dt17  Dt18  Dt19  \n",
       "2644     0     0     0     1     0     0     1     0  \n",
       "3449     0     0     0     0     0     0     0     0  \n",
       "1529     1     1     1     1     1     1     1     1  \n",
       "4200     1     0     0     0     0     0     0     0  \n",
       "1515     1     1     1     1     1     1     1     1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions['pred'] = np.where(test_predictions[test_predictions.columns[1:]].sum(axis=1)>=5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging on Train: accuracy:  0.9314 \n",
      "\n",
      "       no   yes\n",
      "no   1836   123\n",
      "yes    98  1163 \n",
      "\n",
      "Bagging on Test: accuracy:  0.9051 \n",
      "\n",
      "      no  yes\n",
      "no   751   78\n",
      "yes   53  499 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_results(y_train, predictions['pred'], name='Bagging on Train:')\n",
    "classification_results(y_test, test_predictions['pred'], name='Bagging on Test:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dt on Train: accuracy:  0.9248 \n",
      "\n",
      "       no   yes\n",
      "no   1895    64\n",
      "yes   178  1083 \n",
      "\n",
      "Dt on Test: accuracy:  0.9044 \n",
      "\n",
      "      no  yes\n",
      "no   788   41\n",
      "yes   91  461 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=5).fit(X_train, y_train)\n",
    "classification_results(y_train, dt.predict(X_train), name='Dt on Train:')\n",
    "classification_results(y_test, dt.predict(X_test), name='Dt on Test:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging in scikit-learn - BaggingClassifier\n",
    "\n",
    "This ensemble method or meta-classifier is implemented in sk-learn by  BaggingClassifier class.\n",
    "Its main arguments are:\n",
    "* base_estimator - The base algorithm\n",
    "* n_estimators - number of learners fitted to subsets of train set\n",
    "\n",
    "> http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree as a base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dt_base = DecisionTreeClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dt_bagging on Train: accuracy:  0.9345 \n",
      "\n",
      "       no   yes\n",
      "no   1908    51\n",
      "yes   160  1101 \n",
      "\n",
      "Dt_bagging on Test: accuracy:  0.9225 \n",
      "\n",
      "      no  yes\n",
      "no   799   30\n",
      "yes   77  475 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Dt_bagging = BaggingClassifier(base_estimator=Dt_base,\n",
    "                                n_estimators=100, verbose=0)\n",
    "Dt_bagging.fit(X_train, y_train)\n",
    "classification_results(y_train, Dt_bagging.predict(X_train), name='Dt_bagging on Train:')\n",
    "classification_results(y_test, Dt_bagging.predict(X_test), name='Dt_bagging on Test:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Bagging prevent overfitting. Since each model in the collection,is exposed only to sub-set of the train data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest \n",
    "\n",
    "Random forest model, technique actually uses this Begging concept.\n",
    "But Random forest, add verasity to its models, by choosing a different subset of features as well to each bootstrapped sample.\n",
    "\n",
    "but it goes a step ahead to further reduce the variance by randomly choosing a subset of features as well for each bootstrapped sample to make the splits while training (My next post will detail all about Random forest technique)\n",
    "\n",
    "> http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html \n",
    "\n",
    "Lets Compare RandomForest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rd on Train: accuracy:  0.9966 \n",
      "\n",
      "       no   yes\n",
      "no   1959     0\n",
      "yes    11  1250 \n",
      "\n",
      "Rd on Test: accuracy:  0.9413 \n",
      "\n",
      "      no  yes\n",
      "no   802   27\n",
      "yes   54  498 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Rd = RandomForestClassifier()\n",
    "Rd.fit(X_train, y_train)\n",
    "classification_results(y_train, Rd.predict(X_train), name='Rd on Train:')\n",
    "classification_results(y_test, Rd.predict(X_test), name='Rd on Test:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest on big Datasets\n",
    "Since Randomforest don't have the option for incremental learning, its hard to use on large datasets. \n",
    "But we can use the following trick:\n",
    "\n",
    "* Split the data into smaller subsets, that can fit your memory.\n",
    "* Fit random forests to each subset.\n",
    "* append all the underlying trees together in the estimators_ member of one of the trees \n",
    "```\n",
    "for i in range(1, len(forests)):\n",
    "    rf[0].estimators_.extend(forests[i].estimators_)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
