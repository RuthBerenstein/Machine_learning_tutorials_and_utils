{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Models \n",
    "## 3. Advanced ensemble models - Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier, \\\n",
    "    AdaBoostClassifier, GradientBoostingClassifier, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_results(y, y_pred, name='', classes=['no', 'yes'], add_rep=False):\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "                        \n",
    "    cm = pd.DataFrame(confusion_matrix(y, y_pred), \n",
    "                      index=classes, \n",
    "                      columns=classes)\n",
    "\n",
    "    print(name + ' accuracy: ', round(acc,4))\n",
    "    print()\n",
    "    print(cm)\n",
    "    print()\n",
    "    if (add_rep):\n",
    "        print(name + ' Classification report: ')\n",
    "        print(classification_report(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "def regression_results(y_true, y_pred, name=''):\n",
    "    \n",
    "    # Regression metrics\n",
    "    explained_variance=metrics.explained_variance_score(y_true, y_pred)\n",
    "    mean_absolute_error=metrics.mean_absolute_error(y_true, y_pred) \n",
    "    mse=metrics.mean_squared_error(y_true, y_pred) \n",
    "    median_absolute_error=metrics.median_absolute_error(y_true, y_pred)\n",
    "    r2=metrics.r2_score(y_true, y_pred)\n",
    "\n",
    "    print(name )\n",
    "    print('explained_variance: ', round(explained_variance,4))    \n",
    "    print('r2: ', round(r2,4))\n",
    "    print('MAE: ', round(mean_absolute_error,4))\n",
    "    print('MSE: ', round(mse,4))\n",
    "    print('RMSE: ', round(np.sqrt(mse),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Ensemble models, combine the predictions of multiple models, to improve the overall performance. \n",
    "\n",
    "## Simple ensemble Methods\n",
    "\n",
    "Simple ensemble learning methods use a group of existing models, and combine their predictions by voting or avareging. Advanced ensemble models, create a group of models on the given train data set, then combined their predictions in one of simple ensemble methods.\n",
    "\n",
    "\n",
    "Recommended reading:\n",
    "* https://towardsdatascience.com/simple-guide-for-ensemble-learning-methods-d87cc68705a2\n",
    "* https://towardsdatascience.com/holy-grail-for-bias-variance-tradeoff-overfitting-underfitting-7fad64ab5d76\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced ensemble methods\n",
    "\n",
    "## Boosting\n",
    "Boosting is an **iterative technique**, meaning we promote step by step, hopefully to to a better solution.  In each step, we build a model, that is based on a feedback of the previous model.\n",
    "\n",
    "Boosting algorithms, show good predictive accuracy, the best from the models we saw so far. But with it comes high variance and the tendency to overfit.\n",
    "\n",
    "### AdaBoost\n",
    "\n",
    "AdaBoost method, fit a sequence of base models on repeatedly modified versions of the data. At each boosting iteration the samples that were misclassified in the previous iteration are given higher weights, while the correctly-classified samples are given lower weights.\n",
    "\n",
    "\n",
    "It worth noting that since AdaBoost inherently follows problematic samples, it is relatively sensitive to noisy data and outliers.\n",
    "\n",
    "### Gradient descent\n",
    "Gradient descent is a known boosting method, that aims to diminish a given loss function iterativly. In Gradient descent, we step \"down\" the the loss function in the direction of the derivative. \n",
    "\n",
    "### Gradient Boosting \n",
    "\n",
    "Boosting technique, with decision tree as base model, and Gradient decent as boosting method.\n",
    "\n",
    "Gradient Boosting builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. \n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "\n",
    "\n",
    "### XGBoost\n",
    "XGBoost stands for eXtreme Gradient Boosting.\n",
    "It is improved version of the Gradient Boosting. Few of the improvments are:\n",
    "* Xgboost does regularization of the tree as well to avoid overfitting.\n",
    "* Xgboost deals with the missing values efficiently.\n",
    "* Xgboost uses optimization techniques to yield superior results using less computing resources in the shortest amount of time.\n",
    "\n",
    "Following link to learn xgboost:\n",
    "* https://www.youtube.com/watch?v=Vly8xGnNiWs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn AdaBoost\n",
    "\n",
    "Scikit-learn AdaBoost class implements the AdaBoost method. The main arguments are:\n",
    "* base_estimator - the weak learner used.\n",
    "* n_estimators- the maximum number of iterations\n",
    "* learning_rate - The 'size' of the correction in each iterative step, or the amount of impact of the former classifiers on the boosting process.\n",
    "\n",
    "\n",
    "> AdaBoost relatively sensitive to noisy data and outliers,since it tries to improve performance by iteratively clinging to the mis-classified samples.\n",
    "\n",
    "#### AdaBoost example with digits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=0.01, n_estimators=200, random_state=None)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "data = datasets.load_digits()\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,\n",
    "                                                        random_state=0)\n",
    "\n",
    "clf_base = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "clf_adaboost = AdaBoostClassifier(base_estimator=clf_base,\n",
    "                                  n_estimators=200,\n",
    "                                  learning_rate=0.01)\n",
    "clf_adaboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost train accuracy:  0.936\n",
      "\n",
      "     0    1    2    3    4    5    6    7    8    9\n",
      "0  151    0    0    0    0    0    0    0    0    0\n",
      "1    0  103    0    1    0    0    0    0   33   10\n",
      "2    0    0  128    3    0    0    0    0    9    1\n",
      "3    0    0    0  129    0    1    0    1    4   19\n",
      "4    0    0    0    0  148    0    3    0    0    0\n",
      "5    0    0    0    0    0  141    0    0    0    1\n",
      "6    0    0    0    0    0    0  136    0    1    0\n",
      "7    0    0    0    0    0    0    0  136    4    0\n",
      "8    0    0    0    0    0    0    0    0  135    0\n",
      "9    0    0    0    0    0    0    0    1    0  138\n",
      "\n",
      "AdaBoost train Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       151\n",
      "           1       1.00      0.70      0.82       147\n",
      "           2       1.00      0.91      0.95       141\n",
      "           3       0.97      0.84      0.90       154\n",
      "           4       1.00      0.98      0.99       151\n",
      "           5       0.99      0.99      0.99       142\n",
      "           6       0.98      0.99      0.99       137\n",
      "           7       0.99      0.97      0.98       140\n",
      "           8       0.73      1.00      0.84       135\n",
      "           9       0.82      0.99      0.90       139\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      1437\n",
      "   macro avg       0.95      0.94      0.94      1437\n",
      "weighted avg       0.95      0.94      0.94      1437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_results(y_train, clf_adaboost.predict(X_train), name='AdaBoost train', \n",
    "                       classes=data.target_names, add_rep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost test accuracy:  0.8917\n",
      "\n",
      "    0   1   2   3   4   5   6   7   8   9\n",
      "0  25   0   0   1   0   1   0   0   0   0\n",
      "1   0  25   0   1   0   0   0   0   6   3\n",
      "2   0   1  25   5   0   0   0   0   5   0\n",
      "3   0   0   0  26   0   0   0   0   1   2\n",
      "4   0   1   0   0  29   0   0   0   0   0\n",
      "5   0   0   0   0   1  36   0   0   0   3\n",
      "6   0   0   0   1   0   0  42   0   1   0\n",
      "7   0   0   0   0   0   0   0  38   1   0\n",
      "8   0   1   0   1   0   0   0   0  37   0\n",
      "9   0   0   0   2   0   1   0   0   0  38\n",
      "\n",
      "AdaBoost test Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        27\n",
      "           1       0.89      0.71      0.79        35\n",
      "           2       1.00      0.69      0.82        36\n",
      "           3       0.70      0.90      0.79        29\n",
      "           4       0.97      0.97      0.97        30\n",
      "           5       0.95      0.90      0.92        40\n",
      "           6       1.00      0.95      0.98        44\n",
      "           7       1.00      0.97      0.99        39\n",
      "           8       0.73      0.95      0.82        39\n",
      "           9       0.83      0.93      0.87        41\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       360\n",
      "   macro avg       0.91      0.89      0.89       360\n",
      "weighted avg       0.91      0.89      0.89       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_results(y_test, clf_adaboost.predict(X_test), name='AdaBoost test', \n",
    "                       classes=data.target_names, add_rep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "          learning_rate=0.01, n_estimators=200, random_state=None)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_base = LogisticRegression()\n",
    "\n",
    "clf_adaboost = AdaBoostClassifier(base_estimator=clf_base,\n",
    "                                  n_estimators=200,\n",
    "                                  learning_rate=0.01)\n",
    "clf_adaboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost train accuracy:  0.9763\n",
      "\n",
      "     0    1    2    3    4    5    6    7    8    9\n",
      "0  151    0    0    0    0    0    0    0    0    0\n",
      "1    0  139    1    0    1    0    0    0    4    2\n",
      "2    0    1  140    0    0    0    0    0    0    0\n",
      "3    0    0    0  151    0    0    0    0    2    1\n",
      "4    0    1    0    0  147    0    0    0    3    0\n",
      "5    0    0    0    0    0  138    1    0    0    3\n",
      "6    0    2    0    0    1    0  133    0    1    0\n",
      "7    0    0    0    0    0    0    0  138    1    1\n",
      "8    0    3    0    0    0    0    0    0  132    0\n",
      "9    0    0    0    1    0    1    0    0    3  134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_results(y_train, clf_adaboost.predict(X_train), name='AdaBoost train', \n",
    "                       classes=data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost test accuracy:  0.9611\n",
      "\n",
      "    0   1   2   3   4   5   6   7   8   9\n",
      "0  27   0   0   0   0   0   0   0   0   0\n",
      "1   0  31   0   0   0   0   1   0   1   2\n",
      "2   0   0  34   0   0   0   0   1   1   0\n",
      "3   0   0   0  29   0   0   0   0   0   0\n",
      "4   0   0   0   0  29   0   0   1   0   0\n",
      "5   0   0   0   0   0  39   0   0   0   1\n",
      "6   0   1   0   0   0   0  43   0   0   0\n",
      "7   0   0   0   0   2   0   0  37   0   0\n",
      "8   0   1   1   0   0   0   0   0  37   0\n",
      "9   0   0   0   0   0   1   0   0   0  40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_results(y_test, clf_adaboost.predict(X_test), name='AdaBoost test', \n",
    "                       classes=data.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost regression example with Boston data\n",
    "In the following example, we compare Decision tree regressor to AdaBoost regressor that is based on this decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_boston()\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,\n",
    "                                                        random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree train\n",
      "explained_variance:  0.8291\n",
      "r2:  0.8291\n",
      "MAE:  2.739\n",
      "MSE:  14.5504\n",
      "RMSE:  3.8145\n",
      "\n",
      "Decision Tree test\n",
      "explained_variance:  0.5937\n",
      "r2:  0.5897\n",
      "MAE:  3.5791\n",
      "MSE:  33.4113\n",
      "RMSE:  5.7802\n"
     ]
    }
   ],
   "source": [
    "base_dt = DecisionTreeRegressor(max_depth=3)\n",
    "base_dt.fit(X_train, y_train)\n",
    "regression_results(y_train, base_dt.predict(X_train),'Decision Tree train')\n",
    "print()\n",
    "regression_results(y_test, base_dt.predict(X_test),'Decision Tree test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=3, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best'),\n",
       "         learning_rate=0.01, loss='linear', n_estimators=200,\n",
       "         random_state=None)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dt = DecisionTreeRegressor(max_depth=3)\n",
    "\n",
    "adaboost = AdaBoostRegressor(base_estimator=base_dt,\n",
    "                                  n_estimators=200,\n",
    "                                  learning_rate=0.01)\n",
    "adaboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost with Decision Tree train\n",
      "explained_variance:  0.9017\n",
      "r2:  0.9016\n",
      "MAE:  2.2495\n",
      "MSE:  8.3792\n",
      "RMSE:  2.8947\n"
     ]
    }
   ],
   "source": [
    "regression_results(y_train, adaboost.predict(X_train),'AdaBoost with Decision Tree train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost with Decision Tree test\n",
      "explained_variance:  0.676\n",
      "r2:  0.6758\n",
      "MAE:  3.2333\n",
      "MSE:  26.3965\n",
      "RMSE:  5.1378\n"
     ]
    }
   ],
   "source": [
    "regression_results(y_test, adaboost.predict(X_test),'AdaBoost with Decision Tree test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost regressor with Linear regression as base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression train\n",
      "explained_variance:  0.773\n",
      "r2:  0.773\n",
      "MAE:  3.1032\n",
      "MSE:  19.3265\n",
      "RMSE:  4.3962\n",
      "\n",
      "LinearRegression test\n",
      "explained_variance:  0.5901\n",
      "r2:  0.5892\n",
      "MAE:  3.8429\n",
      "MSE:  33.449\n",
      "RMSE:  5.7835\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "base_lr = LinearRegression()\n",
    "base_lr.fit(X_train, y_train)\n",
    "regression_results(y_train, base_lr.predict(X_train),'LinearRegression train')\n",
    "print()\n",
    "regression_results(y_test, base_lr.predict(X_test),'LinearRegression test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False),\n",
       "         learning_rate=0.01, loss='linear', n_estimators=200,\n",
       "         random_state=None)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost = AdaBoostRegressor(base_estimator=base_lr,\n",
    "                                  n_estimators=200,\n",
    "                                  learning_rate=0.01)\n",
    "adaboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostRegressor train\n",
      "explained_variance:  0.7694\n",
      "r2:  0.7677\n",
      "MAE:  3.2944\n",
      "MSE:  19.7783\n",
      "RMSE:  4.4473\n"
     ]
    }
   ],
   "source": [
    "regression_results(y_train, adaboost.predict(X_train),'AdaBoostRegressor train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostRegressor test\n",
      "explained_variance:  0.6085\n",
      "r2:  0.6076\n",
      "MAE:  4.0311\n",
      "MSE:  31.9549\n",
      "RMSE:  5.6529\n"
     ]
    }
   ],
   "source": [
    "regression_results(y_test, adaboost.predict(X_test),'AdaBoostRegressor test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn Gradient boosting - Minimizing  loss function\n",
    "the _GradientBoostingClassifier_ classifier works only with decision trees. so the model hyperparameters are given directly to the _GradientBoostingClassifier_.\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> **NOTE:** The features are always randomly permuted at each split. Therefore, the best found split may vary, even with the same training data and max_features=n_features, if the improvement of the criterion is identical for several splits enumerated during the search of the best split. To obtain a deterministic behaviour during fitting, random_state has to be fixed.\n",
    "\n",
    "### Lets run boston regression with Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1          83.7389            0.30s\n",
      "         2          82.3620            0.25s\n",
      "         3          81.0126            0.26s\n",
      "         4          79.6898            0.24s\n",
      "         5          78.3931            0.25s\n",
      "         6          77.1220            0.24s\n",
      "         7          75.8760            0.23s\n",
      "         8          74.6545            0.23s\n",
      "         9          73.4572            0.22s\n",
      "        10          72.2833            0.23s\n",
      "        20          61.5180            0.19s\n",
      "        30          52.5704            0.17s\n",
      "        40          45.1687            0.15s\n",
      "        50          38.9493            0.13s\n",
      "        60          33.7540            0.12s\n",
      "        70          29.3597            0.11s\n",
      "        80          25.6254            0.10s\n",
      "        90          22.4616            0.09s\n",
      "       100          19.8130            0.08s\n",
      "       200           7.6619            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.01, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=200, n_iter_no_change=None, presort='auto',\n",
       "             random_state=None, subsample=1.0, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_GB = GradientBoostingRegressor(max_depth=3,\n",
    "                                    n_estimators=200,\n",
    "                                    learning_rate=0.01, verbose=1)\n",
    "clf_GB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor train\n",
      "explained_variance:  0.91\n",
      "r2:  0.91\n",
      "MAE:  2.1631\n",
      "MSE:  7.6619\n",
      "RMSE:  2.768\n",
      "\n",
      "GradientBoostingRegressor test\n",
      "explained_variance:  0.7518\n",
      "r2:  0.7518\n",
      "MAE:  3.1145\n",
      "MSE:  20.2105\n",
      "RMSE:  4.4956\n"
     ]
    }
   ],
   "source": [
    "regression_results(y_train, clf_GB.predict(X_train),'GradientBoostingRegressor train')\n",
    "print()\n",
    "regression_results(y_test, clf_GB.predict(X_test),'GradientBoostingRegressor test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification example with Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_digits()\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,\n",
    "                                                        random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1        3215.6313           11.55s\n",
      "         2        3129.8617           11.59s\n",
      "         3        3050.1777           10.36s\n",
      "         4        2975.8496            9.82s\n",
      "         5        2906.0649            9.77s\n",
      "         6        2840.5348            9.66s\n",
      "         7        2778.5467            9.33s\n",
      "         8        2719.7466            9.07s\n",
      "         9        2663.9756            8.87s\n",
      "        10        2610.4905            8.69s\n",
      "        20        2178.1802            7.85s\n",
      "        30        1861.2350            7.47s\n",
      "        40        1613.7877            7.14s\n",
      "        50        1415.8463            6.63s\n",
      "        60        1249.0973            6.13s\n",
      "        70        1107.8564            5.68s\n",
      "        80         987.0129            5.22s\n",
      "        90         882.8483            4.77s\n",
      "       100         791.2592            4.32s\n",
      "       200         283.9247            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.01, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_GB = GradientBoostingClassifier(max_depth=3,\n",
    "                                    n_estimators=200,\n",
    "                                    learning_rate=0.01, verbose=1)\n",
    "clf_GB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier train accuracy:  0.9861\n",
      "\n",
      "     0    1    2    3    4    5    6    7    8    9\n",
      "0  151    0    0    0    0    0    0    0    0    0\n",
      "1    0  146    0    1    0    0    0    0    0    0\n",
      "2    0    0  141    0    0    0    0    0    0    0\n",
      "3    0    1    0  149    0    2    0    1    1    0\n",
      "4    0    0    0    0  149    0    0    1    1    0\n",
      "5    0    0    0    0    0  141    0    0    0    1\n",
      "6    0    0    0    0    0    0  136    0    1    0\n",
      "7    0    0    0    1    0    0    0  137    0    2\n",
      "8    0    2    0    0    0    0    0    0  132    1\n",
      "9    0    0    0    1    0    0    0    1    2  135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_results(y_train, clf_GB.predict(X_train), name='GradientBoostingClassifier train', \n",
    "                       classes=data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier test accuracy:  0.9333\n",
      "\n",
      "    0   1   2   3   4   5   6   7   8   9\n",
      "0  26   0   0   0   0   1   0   0   0   0\n",
      "1   0  32   0   1   0   0   0   0   0   2\n",
      "2   1   0  32   1   0   0   1   1   0   0\n",
      "3   0   0   0  28   0   0   0   0   0   1\n",
      "4   1   0   0   0  28   0   0   1   0   0\n",
      "5   0   1   0   0   0  38   0   0   0   1\n",
      "6   0   0   0   1   1   0  42   0   0   0\n",
      "7   0   0   0   0   1   0   0  38   0   0\n",
      "8   0   2   0   2   0   0   0   0  35   0\n",
      "9   1   0   0   1   0   1   0   0   1  37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_results(y_test, clf_GB.predict(X_test), name='GradientBoostingClassifier test', \n",
    "                       classes=data.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate is importent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_params = {'n_estimators': 200, 'max_leaf_nodes': 3, \n",
    "                   'max_depth': 4, 'random_state': 2,\n",
    "                   'min_samples_split': 5}\n",
    "\n",
    "plt.figure()\n",
    "lr=0.01\n",
    "\n",
    "for label, color, setting in [('learning_rate=0.01',\n",
    "                               'blue',\n",
    "                               {'learning_rate': 0.01}),\n",
    "                              ('learning_rate=0.05', \n",
    "                               'turquoise',\n",
    "                               {'learning_rate': 0.05}), \n",
    "                              ('learning_rate=0.1',\n",
    "                               'magenta',\n",
    "                               {'learning_rate': 0.1})]:\n",
    "    params = dict(original_params)\n",
    "    params.update(setting)\n",
    "\n",
    "    clf = GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # compute test set deviance\n",
    "    test_deviance = np.zeros((params['n_estimators'],), dtype=np.float64)\n",
    "\n",
    "    for i, y_pred in enumerate(clf.staged_decision_function(X_test)):\n",
    "        # clf.loss_ assumes that y_test[i] in {0, 1}\n",
    "        test_deviance[i] = clf.loss_(y_test, y_pred)\n",
    "\n",
    "    plt.plot((np.arange(test_deviance.shape[0]) + 1)[::2], \n",
    "             test_deviance[::2],\n",
    "            '-', color=color, label=label)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Boosting Iterations')\n",
    "plt.ylabel('Test Set Loss- Deviance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1        1130.1151         434.8089           11.75s\n",
      "         2         919.9990         215.3436           12.67s\n",
      "         3         759.4727         141.7806           11.76s\n",
      "         4         629.2751         106.1392           11.69s\n",
      "         5         543.0480          82.3469           11.84s\n",
      "         6         462.0181          67.6475           11.47s\n",
      "         7         399.5957          54.0565           11.15s\n",
      "         8         355.1790          50.0597           10.87s\n",
      "         9         304.8483          37.0921           11.11s\n",
      "        10         271.8585          33.3579           11.14s\n",
      "        20          86.4413           6.9737           10.25s\n",
      "        30          31.6416           1.5343            9.61s\n",
      "        40          13.3038           0.4448            8.91s\n",
      "        50           6.6474           0.3513            8.35s\n",
      "        60           3.3100           0.0925            7.62s\n",
      "        70           1.6292           0.0269            6.91s\n",
      "        80           1.0442           0.0122            6.23s\n",
      "        90           0.5969           0.0044            5.54s\n",
      "       100           0.4007           0.0044            4.84s\n",
      "       200           0.2304          -0.0000            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=4,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=0.5, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_GB = GradientBoostingClassifier(max_depth=4,\n",
    "                                    n_estimators=200,\n",
    "                                    learning_rate=0.1, \n",
    "                                    subsample=0.5,verbose=1)\n",
    "clf_GB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier train accuracy:  1.0\n",
      "\n",
      "     0    1    2    3    4    5    6    7    8    9\n",
      "0  151    0    0    0    0    0    0    0    0    0\n",
      "1    0  147    0    0    0    0    0    0    0    0\n",
      "2    0    0  141    0    0    0    0    0    0    0\n",
      "3    0    0    0  154    0    0    0    0    0    0\n",
      "4    0    0    0    0  151    0    0    0    0    0\n",
      "5    0    0    0    0    0  142    0    0    0    0\n",
      "6    0    0    0    0    0    0  137    0    0    0\n",
      "7    0    0    0    0    0    0    0  140    0    0\n",
      "8    0    0    0    0    0    0    0    0  135    0\n",
      "9    0    0    0    0    0    0    0    0    0  139\n",
      "\n",
      "GradientBoostingClassifier test accuracy:  0.9694\n",
      "\n",
      "    0   1   2   3   4   5   6   7   8   9\n",
      "0  26   0   0   0   0   1   0   0   0   0\n",
      "1   0  34   0   0   1   0   0   0   0   0\n",
      "2   1   0  35   0   0   0   0   0   0   0\n",
      "3   0   0   0  29   0   0   0   0   0   0\n",
      "4   0   0   0   0  29   0   0   1   0   0\n",
      "5   0   0   0   1   0  39   0   0   0   0\n",
      "6   0   0   1   0   0   0  42   0   1   0\n",
      "7   0   0   0   0   0   0   0  39   0   0\n",
      "8   0   0   0   1   0   0   0   0  38   0\n",
      "9   1   0   0   1   0   1   0   0   0  38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_results(y_train, clf_GB.predict(X_train), name='GradientBoostingClassifier train', \n",
    "                       classes=data.target_names)\n",
    "classification_results(y_test, clf_GB.predict(X_test), name='GradientBoostingClassifier test', \n",
    "                       classes=data.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "to install on windows: \n",
    "`conda install -c anaconda py-xgboost ` \n",
    "\n",
    "Example's of regression and classification:\n",
    "* https://www.kaggle.com/stuarthallows/using-xgboost-with-scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_digits()\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,\n",
    "                                                        random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1437, 64), (1437,), (360, 64), (360,))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=4, min_child_weight=1, missing=None, n_estimators=200,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.5, verbose=1)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(max_depth=4,\n",
    "                                    n_estimators=200,\n",
    "                                    learning_rate=0.1, \n",
    "                                    subsample=0.5,verbose=1)\n",
    "\n",
    "\n",
    "xgb_model.fit(X_train, y_train, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier train accuracy:  1.0\n",
      "\n",
      "     0    1    2    3    4    5    6    7    8    9\n",
      "0  151    0    0    0    0    0    0    0    0    0\n",
      "1    0  147    0    0    0    0    0    0    0    0\n",
      "2    0    0  141    0    0    0    0    0    0    0\n",
      "3    0    0    0  154    0    0    0    0    0    0\n",
      "4    0    0    0    0  151    0    0    0    0    0\n",
      "5    0    0    0    0    0  142    0    0    0    0\n",
      "6    0    0    0    0    0    0  137    0    0    0\n",
      "7    0    0    0    0    0    0    0  140    0    0\n",
      "8    0    0    0    0    0    0    0    0  135    0\n",
      "9    0    0    0    0    0    0    0    0    0  139\n",
      "\n",
      "XGBClassifier test accuracy:  0.9667\n",
      "\n",
      "    0   1   2   3   4   5   6   7   8   9\n",
      "0  27   0   0   0   0   0   0   0   0   0\n",
      "1   0  33   0   0   1   0   0   0   0   1\n",
      "2   1   0  35   0   0   0   0   0   0   0\n",
      "3   0   0   0  29   0   0   0   0   0   0\n",
      "4   0   0   0   0  29   0   0   1   0   0\n",
      "5   0   0   0   0   0  38   0   0   0   2\n",
      "6   0   1   0   0   0   0  43   0   0   0\n",
      "7   0   0   0   0   0   0   0  39   0   0\n",
      "8   0   1   0   1   0   0   0   0  37   0\n",
      "9   1   0   0   1   0   1   0   0   0  38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_results(y_train, xgb_model.predict(X_train), name='XGBClassifier train', \n",
    "                       classes=data.target_names)\n",
    "classification_results(y_test, xgb_model.predict(X_test), name='XGBClassifier test', \n",
    "                       classes=data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
